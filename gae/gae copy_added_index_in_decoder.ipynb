{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch_geometric in /environment/miniconda3/lib/python3.11/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (3.7.4)\n",
      "Requirement already satisfied: fsspec in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (3.1.3)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: pyparsing in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /environment/miniconda3/lib/python3.11/site-packages (from torch_geometric) (4.65.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (3.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /environment/miniconda3/lib/python3.11/site-packages (from aiohttp->torch_geometric) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /environment/miniconda3/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torch_geometric) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_tensor(input_tensor, target_length):\n",
    "    input_tensor = input_tensor.unsqueeze(1) \n",
    "    resized_tensor = F.interpolate(\n",
    "        input_tensor, \n",
    "        size=target_length, \n",
    "        mode='linear', \n",
    "        align_corners=False\n",
    "    )\n",
    "    resized_tensor = resized_tensor.squeeze(1)\n",
    "    \n",
    "    return resized_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## labels: day45 baseline 0, day 45 others 1, day90 baseline 2, day others 90 3, day 120 baseline 4, day 120 others 5\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "## labels: day45 baseline 0, day 45 others 1, day90 baseline 2, day others 90 3, day 120 baseline 4, day 120 others 5\n",
    "file_folder = \"/home/featurize/work/ylx/MEA/overfitting\"\n",
    "sub_file_list = os.listdir(file_folder)\n",
    "all_data = []\n",
    "for file_name in sub_file_list:  \n",
    "    file_path = os.path.join(file_folder, file_name)\n",
    "    data_sample = {}\n",
    "    cls_mea = file_name.split(\"_\")[-2]\n",
    "    if cls_mea == \"baseline\":\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    data_sample[\"label\"] = label\n",
    "    df = pd.read_csv(file_path)\n",
    "    data_np = df.values\n",
    "    data_tensor = torch.tensor(data_np, dtype=torch.float32)\n",
    "    target_length = 4570 \n",
    "    data_tensor = resize_tensor(data_tensor, target_length)\n",
    "    data_sample[\"data\"] = data_tensor\n",
    "    data_sample[\"label\"] = label\n",
    "    data_sample[\"data_name\"] = file_name\n",
    "    all_data.append(data_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(all_data, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(all_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(x):\n",
    "  min_val = x.min()\n",
    "  max_val = x.max()\n",
    "  normalized_x = (x - min_val) / (max_val - min_val)\n",
    "  return normalized_x\n",
    "\n",
    "# print(\"Min-Max Normalization (0-1):\\n\", x_normalized_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)#GCN需要改数据形式\n",
    "        \n",
    "        #预测输出形式预判问题\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "      \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        num_sample = x.shape[0]\n",
    "        # print(num_sample)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        max_values, _ = torch.max(x, dim=0)  \n",
    "        \n",
    "        \n",
    "        # print(max_values.unsqueeze(0))\n",
    "        return min_max_normalize(max_values).unsqueeze(0), num_sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(256,4570)\n",
    "        self.linear2 = nn.Linear(4570,8000)\n",
    "        self.linear3 = nn.Linear(8000,4570)\n",
    "        self.linear4 = nn.Linear(4570,4570)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, num_samples):\n",
    "        # noise  = 0.1 * torch.randn(num_samples, 256)\n",
    "        # noise  = noise.to(\"cuda\")\n",
    "        # x = x + noise\n",
    "        #x复制n份（repeat）变成一个tensor，\n",
    "        #decode的结果打印出来\n",
    "        #算meansquare，按道理是一样的，任务是验证这一点？\n",
    "        #reproducable，minimal example\n",
    "        x = self.linear1(x) # \n",
    "        x1 = x\n",
    "        x = F.relu(x) \n",
    "        x = self.linear2(x)  # \n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x) + x1# \n",
    "        x = F.relu(x) \n",
    "        x = self.linear4(x)  # \n",
    "        # 激活函数\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Decoder(torch.nn.Module):\n",
    "#     def __init__(self, num_node_features, hidden_channels):\n",
    "#         super().__init__()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         return x\n",
    "     # 生成标准正态分布的噪声，形状为 (num_samples, 256) \n",
    "# import torch.nn as nn\n",
    "# class Decoder(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.linear1 = nn.Linear(256,4570)\n",
    "#         self.linear2 = nn.Linear(4570,8000)\n",
    "#         self.linear3 = nn.Linear(8000,4570)\n",
    "#         self.linear4 = nn.Linear(4570,4570)\n",
    "        \n",
    "        \n",
    "\n",
    "#     def forward(self, x, num_samples):\n",
    "#         noise  = 0.1 * torch.randn(num_samples, 256)\n",
    "#         noise  = noise.to(\"cuda\")\n",
    "#         x = x+noise\n",
    "#         #x复制n份（repeat）变成一个tensor，\n",
    "#         #decode的结果打印出来\n",
    "#         #算meansquare，按道理是一样的，任务是验证这一点？\n",
    "#         reproducable，minimal example\n",
    "#         x = self.linear1(x) # \n",
    "#         x1 = x\n",
    "#         x = F.relu(x) \n",
    "#         x = self.linear2(x)  # \n",
    "#         x = F.relu(x)\n",
    "#         x = self.linear3(x) + x1# \n",
    "#         x = F.relu(x) \n",
    "#         x = self.linear4(x)  # \n",
    "#         # 激活函数\n",
    "        \n",
    "#         return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):  \n",
    "    def __init__(self, num_node_features, hidden_channels):  \n",
    "        super().__init__()  \n",
    "        self.encoder = Encoder(num_node_features, hidden_channels)  \n",
    "        self.decoder = Decoder() \n",
    "    def forward(self, x, edge_index, batch):  \n",
    "        # Encode the input  \n",
    "        encoded, num_sample = self.encoder(x, edge_index, batch)\n",
    "        #added\n",
    "        print(\"encode_shape:\", encoded.shape)\n",
    "        print(\"encoded.unsqueeze(0).shape:\", encoded.unsqueeze(0).shape)\n",
    "        print(\"x.shape: \", x.shape)\n",
    "        print(\"repeat_shape:\", x.shape[0])\n",
    "        encode_copy = encoded.repeat(x.shape[0], 1)\n",
    "        def add_indices(tensor):\n",
    "            \"\"\"\n",
    "            在每一行末端添加一个index.\n",
    "            \n",
    "            \"\"\"\n",
    "            device = tensor.device\n",
    "            rows = tensor.shape[0]\n",
    "            indices = torch.arange(1, rows + 1,device = device).float().reshape(-1, 1)\n",
    "            return torch.cat((tensor, indices),  dim=1)\n",
    "        \n",
    "        encode_copy_added_index = add_indices(encode_copy)\n",
    "            \n",
    "             \n",
    "        print(\"encode_copy:\", encode_copy)  \n",
    "        print(\"encode_copy.shape\", encode_copy.shape)\n",
    "        decoded = self.decoder(encoded.unsqueeze(0),num_sample)\n",
    "        \n",
    "        \n",
    "        #added\n",
    "        print(\"decode:\", decoded) \n",
    "        print(\"decoded.shape\", decoded.shape)\n",
    "        decoded_of_encode_copy = self.decoder(encode_copy_added_index, num_sample)\n",
    "        print(\"decoded_of_encode_copy_added_index:\", decoded_of_encode_copy)\n",
    "        print(\"decoded_of_encode_copy_added_index.shape\", decoded_of_encode_copy.shape)\n",
    "        return decoded  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "num_node_features = 4570\n",
    "hidden_channels = 256\n",
    "model = Autoencoder(num_node_features, hidden_channels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 111\n",
      "node_features.shape: torch.Size([111, 4570])\n",
      "torch.Size([2, 110])\n"
     ]
    }
   ],
   "source": [
    "num_graphs = len(all_data) \n",
    "graphs = []\n",
    "for i in range(num_graphs):\n",
    "    graph = all_data[i]\n",
    "    num_nodes = int(graph['data'].shape[0])  # 每个图的节点数目\n",
    "    print(\"num_nodes:\", num_nodes)\n",
    "    node_features = graph['data']            # 节点特征矩阵\n",
    "    print(\"node_features.shape:\", node_features.shape)\n",
    "    # 创建依次连接的边缘索引\n",
    "    edge_index = []\n",
    "    for i in range(num_nodes - 1):\n",
    "        edge_index.append([i, i+1])\n",
    "    # 转换为PyTorch张量\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()# 转置并连接，[[0,1],[1,2],[2,3],...]变成[[0,1,2,3,...],[1,2,3,4,...]]\n",
    "    # edge_index.append([i+1, i])                      # 如果图是无向的，添加反方向的边\n",
    "    print(edge_index.shape)\n",
    "    y = torch.tensor([graph['label']], dtype=torch.long)\n",
    "    graph_data = Data(x=node_features, edge_index=edge_index, y=y)\n",
    "    graphs.append(graph_data)\n",
    "random.seed(42)\n",
    "random.shuffle(graphs)\n",
    "train_graphs = graphs \n",
    "# test_graphs = graphs[int(num_graphs*0.8):]    # 后20%作为测试集\n",
    "train_loader = DataLoader(train_graphs, batch_size=1, shuffle=False)\n",
    "# test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_shape: torch.Size([1, 256])\n",
      "encoded.unsqueeze(0).shape: torch.Size([1, 1, 256])\n",
      "x.shape:  torch.Size([111, 4570])\n",
      "repeat_shape: 111\n",
      "encode_copy: tensor([[0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286],\n",
      "        [0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286],\n",
      "        [0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286],\n",
      "        ...,\n",
      "        [0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286],\n",
      "        [0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286],\n",
      "        [0.0826, 0.3475, 0.3146,  ..., 0.1937, 0.5253, 0.1286]],\n",
      "       device='cuda:0', grad_fn=<RepeatBackward0>)\n",
      "encode_copy.shape torch.Size([111, 256])\n",
      "decode: tensor([[[ 0.2288, -0.1293,  0.1112,  ..., -0.1652,  0.0214, -0.0374]]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "decoded.shape torch.Size([1, 1, 4570])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (111x257 and 256x4570)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(f\"Shape of data.x: {data.x.shape}\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# encode= encoder(data.x, data.edge_index, data.batch)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(f\"Encode shape: {encode.shape}\")\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m decode \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# decode = decoder(encode_copy, data.edge_index, data.batch)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(f\"Decoded output shape: {decode.shape}\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss(decode, data\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 35\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode:\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoded) \n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m decoded_of_encode_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode_copy_added_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_of_encode_copy_added_index:\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoded_of_encode_copy)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoded_of_encode_copy_added_index.shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoded_of_encode_copy\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 20\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, num_samples)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, num_samples):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# noise  = 0.1 * torch.randn(num_samples, 256)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# noise  = noise.to(\"cuda\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#算meansquare，按道理是一样的，任务是验证这一点？\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#reproducable，minimal example\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     21\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x) \n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (111x257 and 256x4570)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epoch = 10000   \n",
    "lerning_rate = 0.01\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lerning_rate, capturable=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoch, eta_min=0.000001)\n",
    "mse_loss = torch.nn.MSELoss() \n",
    "loss_values = []\n",
    "tttt=torch.randn(1, 256)\n",
    "for epoch in tqdm(range(epoch)):\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        # print(f\"Shape of data.x: {data.x.shape}\")\n",
    "        # encode= encoder(data.x, data.edge_index, data.batch)\n",
    "        # print(f\"Encode shape: {encode.shape}\")\n",
    "        \n",
    "        decode = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        # decode = decoder(encode_copy, data.edge_index, data.batch)\n",
    "        # print(f\"Decoded output shape: {decode.shape}\")\n",
    "\n",
    "        loss = mse_loss(decode, data.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    loss_values.append(avg_loss)\n",
    "    if epoch%500==0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_loss}')\n",
    "\n",
    "    # 训练完成后保存模型权重\n",
    "model_path = f'gcn_model_ep_{epoch}_lr_{lerning_rate}_hidden_{hidden_channels}.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f'Model saved to {model_path}')\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "# 保存图像到本地文件\n",
    "loss_curve_path = f'training_loss_curve_ep_{epoch}_lr_{lerning_rate}_hidden_{hidden_channels}.png'\n",
    "plt.savefig(loss_curve_path)\n",
    "plt.show()\n",
    "\n",
    "# 测试模式\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     # for data in test_loader:\n",
    "#     for data in train_loader:\n",
    "\n",
    "#         data = data.to(device)\n",
    "#         out = model(data.x, data.edge_index, data.batch)\n",
    "#         pred = out.argmax(dim=1)\n",
    "#         correct += int((pred == data.y).sum())\n",
    "#         total += data.num_graphs\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     # 遍历训练集或测试集\n",
    "#     for data in train_loader:\n",
    "#         data = data.to(device)\n",
    "        \n",
    "#         # 编码器进行编码\n",
    "#         encode = encoder(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "#         # 假设最终模型需要对编码结果进行分类 (也许解码器不是必要的，取决于你的模型设计)\n",
    "#         # 如果你想对节点进行分类，可以直接用编码结果进行分类\n",
    "#         # 例如，你可能有一个全连接层来将编码结果映射到类别空间：\n",
    "#         # out = model_classifier(encode)\n",
    "        \n",
    "#         # 对于分类任务，我们通常会使用 `argmax` 选择最大概率的类别\n",
    "#         pred = encode.argmax(dim=1)\n",
    "        \n",
    "#         # 计算正确的预测和总预测数\n",
    "#         correct += (pred == data.y).sum().item()\n",
    "#         total += data.num_graphs\n",
    "\n",
    "#     accuracy = correct / total\n",
    "#     print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# accuracy = correct / total\n",
    "# print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # 加载模型权重进行测试\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "# print(f'Model loaded from {model_path}')\n",
    "\n",
    "# # 收集预测和标签\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # for data in test_loader:     # 确保这里使用的是测试数据加载器\n",
    "#     for data in train_loader:  # 确保这里使用的是测试数据加载器\n",
    "\n",
    "#         # data = data.to(device)\n",
    "#         data = {key: value.to(device) for key, value in data.items()}\n",
    "#         out = model(data.x, data.edge_index, data.batch)\n",
    "#         pred = out.argmax(dim=1)\n",
    "#         all_preds.extend(pred.cpu().tolist())\n",
    "#         all_labels.extend(data.y.cpu().tolist())\n",
    "\n",
    "# # 计算混淆矩阵\n",
    "# conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# # 提取混淆矩阵的值\n",
    "# TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# # 计算准确率 (Accuracy)\n",
    "# accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# # 计算精确率 (Precision)\n",
    "# precision = TP / (TP + FP)\n",
    "# print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# # 计算召回率 (Recall)\n",
    "# recall = TP / (TP + FN)\n",
    "# print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# # 可视化混淆矩阵\n",
    "# fig, ax = plt.subplots(figsize=(4, 3))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "\n",
    "# # 标注 TP, FP, TN, FN\n",
    "# labels = ['TN', 'FP', 'FN', 'TP']\n",
    "# for i in range(2):\n",
    "#     for j in range(2):\n",
    "#         ax.text(j, i, f\"{labels[i * 2 + j]}={conf_matrix[i, j]}\", ha='center', va='center', color='red')\n",
    "\n",
    "# ax.set_xlabel('Predicted Labels')\n",
    "# ax.set_ylabel('True Labels')\n",
    "# ax.set_title('Confusion Matrix with Annotations')\n",
    "# plt.show()\n",
    "\n",
    "# accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "# print(f'Test Accuracy: {accuracy}')\n",
    "# print(f'all_labels: {all_labels}')\n",
    "# print(f'all_preds: {all_preds}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
